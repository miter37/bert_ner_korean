{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bertner_korean_NER",
      "provenance": [],
      "collapsed_sections": [
        "HHcMdgReJaMr",
        "P4PPj2wopVGQ",
        "KhNBv4HPqhDa",
        "JjjP3nQ7L5QK",
        "YfGUmHvDMGrz"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02f51e6fa79040d78a186a551ccdc464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e3b081fca758425c9ef33be0df93b69a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_12c0451daa8f40489a15e08da44cabea",
              "IPY_MODEL_5358b1acc9ed42dba9309d9abc127609"
            ]
          }
        },
        "e3b081fca758425c9ef33be0df93b69a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12c0451daa8f40489a15e08da44cabea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c4ce565ea2ba40219cc5c04f3dcc27f7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0bef68485967477fa9305d2b2ede554e"
          }
        },
        "5358b1acc9ed42dba9309d9abc127609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e8443113999544a784d0fb140dea3dc4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [00:00&lt;00:00, 761B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b1fbac03468a4d2f8b777f8cc8964e1b"
          }
        },
        "c4ce565ea2ba40219cc5c04f3dcc27f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0bef68485967477fa9305d2b2ede554e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8443113999544a784d0fb140dea3dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b1fbac03468a4d2f8b777f8cc8964e1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6955c2eb55244f359631fe10c1e2a4cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_98cc478b176c4ec29c44b8114bbd6dd9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5131a47a63494432a5bfd687f57394ec",
              "IPY_MODEL_10c7352cfc164e5da4209b30c328e9bd"
            ]
          }
        },
        "98cc478b176c4ec29c44b8114bbd6dd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5131a47a63494432a5bfd687f57394ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_beef252bb9dc4fd1903825c9e1ea83b0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f115140b8e40403d94f7b9d2653b1bc3"
          }
        },
        "10c7352cfc164e5da4209b30c328e9bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ed1cb3010ff64d92a0b680541214aa62",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 996k/996k [00:01&lt;00:00, 967kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_463f47f14e8042a982163cc1c57256c7"
          }
        },
        "beef252bb9dc4fd1903825c9e1ea83b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f115140b8e40403d94f7b9d2653b1bc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed1cb3010ff64d92a0b680541214aa62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "463f47f14e8042a982163cc1c57256c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "48a81e606a6d4df1a566557a1355e592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_85157fa6bccd41bf9b7f7a5ae54bf3e6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_daa1f418a4ac4259bd799e89f4181570",
              "IPY_MODEL_942eb6ebc03f4a9a94daddfac42b6445"
            ]
          }
        },
        "85157fa6bccd41bf9b7f7a5ae54bf3e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "daa1f418a4ac4259bd799e89f4181570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a61fabe916524ac0810fb2c03d907318",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1083389348,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1083389348,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd35c2b415604fde92f86bb18ba34a5a"
          }
        },
        "942eb6ebc03f4a9a94daddfac42b6445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f3d1499ebdcb478d98a5bbe0d29e1ece",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.08G/1.08G [01:46&lt;00:00, 10.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff4c17e38bb644a98f95bc1442d53acd"
          }
        },
        "a61fabe916524ac0810fb2c03d907318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd35c2b415604fde92f86bb18ba34a5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3d1499ebdcb478d98a5bbe0d29e1ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff4c17e38bb644a98f95bc1442d53acd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miter37/bert_ner_korean/blob/main/bertner_korean_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHcMdgReJaMr"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXksuj9u4Y87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a476f9d-63ce-40c6-ad27-7f1dbf5ae982"
      },
      "source": [
        "'''\n",
        "참고한 사이트\n",
        "#### 케라스 BERT 관련 예제 : https://keras.io/examples/nlp/semantic_similarity_with_bert/\n",
        "#### BERT 입력값 관련 전처리 : https://androidkt.com/name-entity-recognition-with-bert-in-tensorflow/\n",
        "#### 한글 NER 데이터 및 국내 KoBERT + CRF 참고 : https://github.com/eagle705/pytorch-bert-crf-ner \n",
        "#### LSTM 적용 : https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb\n",
        "#### Keras BERT 적용 라이브러리 : https://huggingface.co/transformers/model_doc/bert.html?highlight=tfbertmodel#tfbertmodel\n",
        "#### KoBERT huggingface Transformer 적용 : https://github.com/monologg/KoBERT-Transformers\n",
        "\n",
        "'''\n",
        "!nvidia-smi -L\n",
        "%tensorflow_version 2.x\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"현재 TF버젼: \",tf.version.VERSION)\n",
        "print(\"현재 Keras버젼: \", tf.keras.__version__)\n",
        "print(\"Colab Pro, GPU Tesla V100, TF 2.3, Keras 2.4 사용함\")\n",
        "\n",
        "## 경로 지정 : 파일들 설치한 경로를 써주면 됨.\n",
        "path = '/content/mnt/My Drive/Colab Notebooks/project-2nd seme/BERTNER_2020팀프로젝트/version3'\n",
        "#path = '/content/mnt/Shareddrives/AI-EDU/알고리즘/BERTNER'\n",
        "'''구글 드라이브 마운팅'''\n",
        "import os, sys \n",
        "from google.colab import drive \n",
        "drive.mount('/content/mnt') \n",
        "\n",
        "!pip install transformers==3.0.0\n",
        "!pip install seqeval\n",
        "!pip install sklearn_crfsuite\n",
        "#!pip3 install kobert-transformers\n",
        "#!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-3404febe-8d81-6fda-16b0-435216d8531e)\n",
            "현재 TF버젼:  2.3.0\n",
            "현재 Keras버젼:  2.4.0\n",
            "Colab Pro, GPU Tesla V100, TF 2.3, Keras 2.4 사용함\n",
            "Drive already mounted at /content/mnt; to attempt to forcibly remount, call drive.mount(\"/content/mnt\", force_remount=True).\n",
            "Requirement already satisfied: transformers==3.0.0 in /usr/local/lib/python3.6/dist-packages (3.0.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (0.1.94)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (1.18.5)\n",
            "Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (0.8.0rc4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (0.8)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (0.0.43)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (20.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.0) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (1.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (0.17.0)\n",
            "Requirement already satisfied: sklearn_crfsuite in /usr/local/lib/python3.6/dist-packages (0.3.6)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.7)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.9.7)\n",
            "Requirement already satisfied: kobert-transformers in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: transformers>=2.9.1 in /usr/local/lib/python3.6/dist-packages (from kobert-transformers) (3.0.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from kobert-transformers) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.1->kobert-transformers) (1.18.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.1->kobert-transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.1->kobert-transformers) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.1->kobert-transformers) (0.1.94)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.1->kobert-transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.1->kobert-transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.1->kobert-transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.1->kobert-transformers) (4.41.1)\n",
            "Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.1->kobert-transformers) (0.8.0rc4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.1->kobert-transformers) (20.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->kobert-transformers) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->kobert-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.9.1->kobert-transformers) (0.17.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.9.1->kobert-transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.9.1->kobert-transformers) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.9.1->kobert-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.9.1->kobert-transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.9.1->kobert-transformers) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.9.1->kobert-transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=2.9.1->kobert-transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J7cNp274ZHM"
      },
      "source": [
        "'''주요 라이브러리 임포트'''\n",
        "#%tensorflow_version 2.x\n",
        "#import tensorflow as tf\n",
        "#print(tf.__version__)\n",
        "\n",
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "from transformers import ( TF2_WEIGHTS_NAME, BertConfig,\n",
        "    BertTokenizer, BertModel, TFBertModel, create_optimizer)\n",
        "from kobert_transformers import get_kobert_model, get_distilkobert_model\n",
        "\n",
        "from seqeval.metrics import classification_report,accuracy_score,f1_score\n",
        "from tqdm import tqdm,trange\n",
        "\n",
        "\n",
        "'''뒤에 발생한 의문의 멈춤현상을 잡기위한 코드'''\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)  #https://github.com/huggingface/transformers/issues/5505#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4PPj2wopVGQ"
      },
      "source": [
        "#데이터 세팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ficS7HXPbHrk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "55fe633e-7015-4f64-fac9-d0ad1b4ac2ee"
      },
      "source": [
        "''' (시간오래걸림) 한글 ner 데이터 text파일을 하나로 합치는 과정. 한번 했으면 실행할 필요 없음 '''\n",
        "## concatenate_texts 파일 있으면 실행하지 않아도 됨\n",
        "'''\n",
        "## https://hoood.tistory.com/300\n",
        "cd /content/mnt/My Drive/Colab Notebooks/project-2nd seme/NER_kaggle예제/korean_ner_label\n",
        "import glob\n",
        "\n",
        "path = '/content/mnt/My Drive/Colab Notebooks/project-2nd seme/NER_kaggle예제/korean_ner_label'\n",
        "os.chdir(path)\n",
        "\n",
        "if os.path.exists(\"concatenate_texts.txt\"):\n",
        "    os.rename(\"concatenate_texts.txt\", \"concatenate_texts_original.txt\")\n",
        "else:\n",
        "    print(\"The file does not exist\")\n",
        "\n",
        "read_files = glob.glob(\"*.txt\")\n",
        "\n",
        "print(read_files)\n",
        "\n",
        "with open(\"concatenate_texts.txt\", \"wb\") as outfile:\n",
        "    for f in read_files:\n",
        "        i = 0\n",
        "        line = \"***********\" + f + \"***********\" + \"\\n\\n\"\n",
        "        i += 1\n",
        "        outfile.write(line.encode('utf-8'))\n",
        "        with open(f, \"rb\") as infile:\n",
        "            outfile.write(infile.read())'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n## https://hoood.tistory.com/300\\ncd /content/mnt/My Drive/Colab Notebooks/project-2nd seme/NER_kaggle예제/korean_ner_label\\nimport glob\\n\\npath = \\'/content/mnt/My Drive/Colab Notebooks/project-2nd seme/NER_kaggle예제/korean_ner_label\\'\\nos.chdir(path)\\n\\nif os.path.exists(\"concatenate_texts.txt\"):\\n    os.rename(\"concatenate_texts.txt\", \"concatenate_texts_original.txt\")\\nelse:\\n    print(\"The file does not exist\")\\n\\nread_files = glob.glob(\"*.txt\")\\n\\nprint(read_files)\\n\\nwith open(\"concatenate_texts.txt\", \"wb\") as outfile:\\n    for f in read_files:\\n        i = 0\\n        line = \"***********\" + f + \"***********\" + \"\\n\\n\"\\n        i += 1\\n        outfile.write(line.encode(\\'utf-8\\'))\\n        with open(f, \"rb\") as infile:\\n            outfile.write(infile.read())'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2eJepGJ77k_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb61ab94-3922-4d4a-a6d0-381f93335a86"
      },
      "source": [
        "''' 한글 ner 학습데이터가 합쳐진 concatenate_texts 불러와서 정리 '''\n",
        "\n",
        "file_full_name=path + '/concatenate_text.txt'\n",
        "with open(file_full_name, 'r') as textfile:\n",
        "  kor_ner_dataset = []\n",
        "  sen_num = 1\n",
        "  for row in textfile:\n",
        "    if row[0:3] != \"***\" :\n",
        "      if row[0] != \"#\": \n",
        "        if row[0] != \"_\":\n",
        "          if row == \"\\n\":\n",
        "            sen_num += 1\n",
        "          else :\n",
        "            row2 = row.replace(\"\\n\",\"\")\n",
        "            row3 = row2.split(\"\\t\")\n",
        "            row3.insert(0,\"sen_\"+str(sen_num))\n",
        "            #print(row3)\n",
        "            kor_ner_dataset.append(row3)\n",
        "\n",
        "\n",
        "## 읽은 txt를 판다스 데이터프레임으로 변환하고 컬럼명 지정해줌\n",
        "df_data = pd.DataFrame(kor_ner_dataset)\n",
        "df_data.columns = ['Sentence #', 'Word', \"Word_2\", 'POS', 'Tag']\n",
        "print(df_data.head())\n",
        "print(df_data.shape)\n",
        "\n",
        "## n/a 값 정리\n",
        "print(df_data.isnull().sum())\n",
        "df_data = df_data.dropna()\n",
        "print(df_data.isnull().sum())\n",
        "print(df_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Sentence # Word Word_2  POS    Tag\n",
            "0      sen_2    강      강  NNP  B-PER\n",
            "1      sen_2    씨      씨  NNB      O\n",
            "2      sen_2    는      는   JX      O\n",
            "3      sen_2    “      “   SS      O\n",
            "4      sen_2   처음     처음  NNG      O\n",
            "(725485, 5)\n",
            "Sentence #    0\n",
            "Word          0\n",
            "Word_2        1\n",
            "POS           1\n",
            "Tag           1\n",
            "dtype: int64\n",
            "Sentence #    0\n",
            "Word          0\n",
            "Word_2        0\n",
            "POS           0\n",
            "Tag           0\n",
            "dtype: int64\n",
            "(725484, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vznYdw87PbcJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a458989-0195-4881-8421-6309d2a2c7f2"
      },
      "source": [
        "## tag의 종류 뽑아내기\n",
        "tag_list=df_data.Tag.unique()\n",
        "# ascending=False 하면 내림차순\n",
        "tag_list =  np.sort(tag_list)[::-1]\n",
        "\n",
        "print(tag_list) \n",
        "print(len(tag_list))\n",
        "\n",
        "label_map = {label: i+1 for i, label in enumerate(tag_list)}   ##tag_list에 레이블 \n",
        "idx2label = {i: w for w, i in label_map.items()}  ##tag_list을 뒤집어 놓은거\n",
        "idx2label[0] = 'Null'\n",
        "num_labels = len(tag_list) +1\n",
        "\n",
        "print(label_map)\n",
        "print(idx2label)\n",
        "\n",
        "idx2label_k = {1: 'O', 2: 'Time', 3: 'Etc', 4: 'Ratio', 5: 'Name', 6: 'Org', 7: 'Etc_No.', 8: 'Money', 9: 'Location', 10: 'Duration', 11: 'Date', 12: 'Time', 13: 'Etc', 14: 'Ratio',\n",
        "               15: 'Name', 16: 'Org', 17: 'Etc_No', 18: 'Money', 19: 'Location', 20: 'Duration', 21: 'Date', 0: 'Null'}\n",
        "print(idx2label_k)\n",
        "#np.save(path +'/idx2label_k',idx2label_k)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['O' 'I-TIM' 'I-POH' 'I-PNT' 'I-PER' 'I-ORG' 'I-NOH' 'I-MNY' 'I-LOC'\n",
            " 'I-DUR' 'I-DAT' 'B-TIM' 'B-POH' 'B-PNT' 'B-PER' 'B-ORG' 'B-NOH' 'B-MNY'\n",
            " 'B-LOC' 'B-DUR' 'B-DAT']\n",
            "21\n",
            "{'O': 1, 'I-TIM': 2, 'I-POH': 3, 'I-PNT': 4, 'I-PER': 5, 'I-ORG': 6, 'I-NOH': 7, 'I-MNY': 8, 'I-LOC': 9, 'I-DUR': 10, 'I-DAT': 11, 'B-TIM': 12, 'B-POH': 13, 'B-PNT': 14, 'B-PER': 15, 'B-ORG': 16, 'B-NOH': 17, 'B-MNY': 18, 'B-LOC': 19, 'B-DUR': 20, 'B-DAT': 21}\n",
            "{1: 'O', 2: 'I-TIM', 3: 'I-POH', 4: 'I-PNT', 5: 'I-PER', 6: 'I-ORG', 7: 'I-NOH', 8: 'I-MNY', 9: 'I-LOC', 10: 'I-DUR', 11: 'I-DAT', 12: 'B-TIM', 13: 'B-POH', 14: 'B-PNT', 15: 'B-PER', 16: 'B-ORG', 17: 'B-NOH', 18: 'B-MNY', 19: 'B-LOC', 20: 'B-DUR', 21: 'B-DAT', 0: 'Null'}\n",
            "{1: 'O', 2: 'Time', 3: 'Etc', 4: 'Ratio', 5: 'Name', 6: 'Org', 7: 'Etc_No.', 8: 'Money', 9: 'Location', 10: 'Duration', 11: 'Date', 12: 'Time', 13: 'Etc', 14: 'Ratio', 15: 'Name', 16: 'Org', 17: 'Etc_No', 18: 'Money', 19: 'Location', 20: 'Duration', 21: 'Date', 0: 'Null'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAns5JK3KAWU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c018841-d64f-4a00-bcc5-6815630587a0"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test=train_test_split(df_data,test_size=0.20,shuffle=False)\n",
        "x_train.shape,x_test.shape\n",
        "print(x_train.head())\n",
        "\n",
        "agg_func = lambda s: [ [w,t] for w,t in zip(s[\"Word\"].values.tolist(),s[\"Tag\"].values.tolist())]\n",
        "\n",
        "x_train_grouped = x_train.groupby(\"Sentence #\").apply(agg_func)\n",
        "x_test_grouped = x_test.groupby(\"Sentence #\").apply(agg_func)\n",
        "print(x_train_grouped)\n",
        "\n",
        "x_train_sentences = [[s[0] for s in sent] for sent in x_train_grouped.values]\n",
        "x_test_sentences = [[s[0] for s in sent] for sent in x_test_grouped.values]\n",
        "print(x_train_sentences)\n",
        "\n",
        "x_train_tags = [[t[1] for t in tag] for tag in x_train_grouped.values]\n",
        "x_test_tags = [[t[1] for t in tag] for tag in x_test_grouped.values]\n",
        "print(x_train_tags)\n",
        "\n",
        "print(np.shape(x_train_sentences),np.shape(x_test_sentences))\n",
        "print(np.shape(x_train_tags),np.shape(x_test_tags))\n",
        "print(type(x_train_sentences))\n",
        "print(x_train_sentences[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Sentence # Word Word_2  POS    Tag\n",
            "0      sen_2    강      강  NNP  B-PER\n",
            "1      sen_2    씨      씨  NNB      O\n",
            "2      sen_2    는      는   JX      O\n",
            "3      sen_2    “      “   SS      O\n",
            "4      sen_2   처음     처음  NNG      O\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhNBv4HPqhDa"
      },
      "source": [
        "# BERT 모델 세팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PT59iuRIJwj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "02f51e6fa79040d78a186a551ccdc464",
            "e3b081fca758425c9ef33be0df93b69a",
            "12c0451daa8f40489a15e08da44cabea",
            "5358b1acc9ed42dba9309d9abc127609",
            "c4ce565ea2ba40219cc5c04f3dcc27f7",
            "0bef68485967477fa9305d2b2ede554e",
            "e8443113999544a784d0fb140dea3dc4",
            "b1fbac03468a4d2f8b777f8cc8964e1b",
            "6955c2eb55244f359631fe10c1e2a4cb",
            "98cc478b176c4ec29c44b8114bbd6dd9",
            "5131a47a63494432a5bfd687f57394ec",
            "10c7352cfc164e5da4209b30c328e9bd",
            "beef252bb9dc4fd1903825c9e1ea83b0",
            "f115140b8e40403d94f7b9d2653b1bc3",
            "ed1cb3010ff64d92a0b680541214aa62",
            "463f47f14e8042a982163cc1c57256c7"
          ]
        },
        "outputId": "8c1f49a5-5140-4cc4-8a46-213b07f7215a"
      },
      "source": [
        "''' BERT 모델 설정 '''\n",
        "max_seq_length =128\n",
        "pad_token=0\n",
        "pad_token_segment_id=0\n",
        "sequence_a_segment_id=0\n",
        "pad_token_label_id = 0\n",
        "BERT_MODEL=\"bert-base-multilingual-cased\"\n",
        "config = BertConfig.from_pretrained(BERT_MODEL)     # transformer BERT 라이브러리 사용을 위한 config\n",
        "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL,do_lower_case=False)    # transformer BERT 라이브러리 중 Tokenizer\n",
        "#from kobert_transformers import get_tokenizer\n",
        "#tokenizer = get_tokenizer()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02f51e6fa79040d78a186a551ccdc464",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6955c2eb55244f359631fe10c1e2a4cb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEU86-Es9D1O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f73f650-d2bb-403e-8673-1996832f6f9c"
      },
      "source": [
        "''' BERT모델의 input에 맞는 형식으로 바꿔주는 함수 '''\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from kobert_transformers import get_tokenizer\n",
        "\n",
        "def convert_to_input(sentences,tags):\n",
        "  input_id_list,attention_mask_list,token_type_id_list=[],[],[]\n",
        "  label_id_list=[]\n",
        "  \n",
        "  for x,y in tqdm(zip(sentences,tags),total=len(tags)):\n",
        "  \n",
        "    tokens = []\n",
        "    label_ids = []\n",
        "\n",
        "    for word, label in zip(x, y):\n",
        "      # 단어를 분절시키는 tokenizer 과정\n",
        "      word_tokens = tokenizer.tokenize(word)\n",
        "      tokens.extend(word_tokens)\n",
        "      # Use the real label id for the first token of the word, and padding ids for the remaining tokens\n",
        "      if label[0][0] == \"B\" :\n",
        "        label_ids.extend([label_map[label]] + [label_map[\"I\"+label[1:]]] * (len(word_tokens) - 1))\n",
        "      else :\n",
        "        label_ids.extend([label_map[label]] + [label_map[label]] * (len(word_tokens) - 1))\n",
        "      ### 원본은 label_ids.extend([label_map[label]] + [0] * (len(word_tokens) - 1))  인데 수정함.      \n",
        "  \n",
        "    special_tokens_count =  2\n",
        "    if len(tokens) > max_seq_length - special_tokens_count:\n",
        "      tokens = tokens[: (max_seq_length - special_tokens_count)]\n",
        "      label_ids = label_ids[: (max_seq_length - special_tokens_count)]\n",
        "\n",
        "    label_ids = [pad_token_label_id]+label_ids+[pad_token_label_id]\n",
        "    inputs = tokenizer.encode_plus(tokens,add_special_tokens=True, max_length=max_seq_length)\n",
        "\n",
        "    input_ids, token_type_ids = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
        "    attention_masks = [1] * len(input_ids)\n",
        "\n",
        "    attention_mask_list.append(attention_masks)\n",
        "    input_id_list.append(input_ids)\n",
        "    token_type_id_list.append(token_type_ids)\n",
        "\n",
        "    label_id_list.append(label_ids)\n",
        "\n",
        "  return input_id_list,token_type_id_list,attention_mask_list,label_id_list\n",
        "\n",
        "''' 위 함수를 이용해 변환 작업 '''\n",
        "input_ids_train,token_ids_train,attention_masks_train,label_ids_train=convert_to_input(x_train_sentences,x_train_tags)\n",
        "input_ids_test,token_ids_test,attention_masks_test,label_ids_test=convert_to_input(x_test_sentences,x_test_tags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19188/19188 [00:21<00:00, 899.62it/s]\n",
            "100%|██████████| 4777/4777 [00:05<00:00, 905.70it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-qMhDlM9D6v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baf667be-8510-42a5-e4d0-8b917a57974f"
      },
      "source": [
        "''' 128개 입력값을 받는 BERT 입력값에 맞게 빈칸 채우는 padding작업과, y 결과값을 원핫인코딩 작업 '''\n",
        "\n",
        "## 패딩, 카테고리컬 직전 출력\n",
        "kk =0\n",
        "kk2 = 0\n",
        "print(np.shape(input_ids_train[kk]),np.shape(token_ids_train[kk]),np.shape(attention_masks_train[kk]),np.shape(label_ids_train[kk]))\n",
        "print(np.shape(input_ids_train[kk][kk2]),np.shape(token_ids_train[kk][kk2]),np.shape(attention_masks_train[kk][kk2]),np.shape(label_ids_train[kk][kk2]))\n",
        "print(np.shape(input_ids_train),np.shape(token_ids_train),np.shape(attention_masks_train),np.shape(label_ids_train))\n",
        "print(input_ids_train[kk])\n",
        "print(token_ids_train[kk])\n",
        "print(attention_masks_train[kk])\n",
        "print(label_ids_train[kk])\n",
        "\n",
        "## 훈련데이터 패딩 \n",
        "input_ids_train = pad_sequences(input_ids_train,maxlen=max_seq_length,dtype=\"long\",truncating=\"post\",padding=\"post\")\n",
        "token_ids_train = pad_sequences(token_ids_train,maxlen=max_seq_length,dtype=\"long\",truncating=\"post\",padding=\"post\")\n",
        "attention_masks_train = pad_sequences(attention_masks_train,maxlen=max_seq_length,dtype=\"long\",truncating=\"post\",padding=\"post\")\n",
        "label_ids_train = pad_sequences(label_ids_train,maxlen=max_seq_length,dtype=\"long\",truncating=\"post\",padding=\"post\")\n",
        "## 테스트 데이터 패딩\n",
        "input_ids_test = pad_sequences(input_ids_test,maxlen=max_seq_length,dtype=\"long\",truncating=\"post\",padding=\"post\")\n",
        "token_ids_test = pad_sequences(token_ids_test,maxlen=max_seq_length,dtype=\"long\",truncating=\"post\",padding=\"post\")\n",
        "attention_masks_test = pad_sequences(attention_masks_test,maxlen=max_seq_length,dtype=\"long\",truncating=\"post\",padding=\"post\")\n",
        "label_ids_test = pad_sequences(label_ids_test,maxlen=max_seq_length,dtype=\"long\",truncating=\"post\",padding=\"post\")\n",
        "\n",
        "## y 결과값 카테고리 원핫인코딩화\n",
        "from keras.utils import to_categorical\n",
        "label_ids_train2 = [to_categorical(i, num_classes = num_labels) for i in label_ids_train]\n",
        "label_ids_test2 = [to_categorical(i, num_classes = num_labels) for i in label_ids_test]\n",
        "\n",
        "#패딩, 카테고리컬 직후 출력\n",
        "print(np.shape(input_ids_train[kk]),np.shape(token_ids_train[kk]),np.shape(attention_masks_train[kk]),np.shape(label_ids_train2[kk]))\n",
        "print(np.shape(input_ids_train[kk][kk2]),np.shape(token_ids_train[kk][kk2]),np.shape(attention_masks_train[kk][kk2]),np.shape(label_ids_train2[kk][kk2]))\n",
        "print(np.shape(input_ids_train),np.shape(token_ids_train),np.shape(attention_masks_train),np.shape(label_ids_train2))\n",
        "print(input_ids_train[kk])\n",
        "print(token_ids_train[kk])\n",
        "print(attention_masks_train[kk])\n",
        "print(label_ids_train2[kk])\n",
        "print(type(input_ids_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(26,) (26,) (26,) (26,)\n",
            "() () () ()\n",
            "(19188,) (19188,) (19188,) (19188,)\n",
            "[101, 8924, 118866, 35979, 39671, 23545, 24178, 9637, 9460, 48549, 9043, 9074, 66982, 9328, 18622, 14843, 9460, 9555, 9633, 107657, 9202, 9044, 9557, 9056, 119, 102]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "[0, 1, 1, 1, 1, 16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
            "(128,) (128,) (128,) (128, 22)\n",
            "() () () (22,)\n",
            "(19188, 128) (19188, 128) (19188, 128) (19188, 128, 22)\n",
            "[   101   8924 118866  35979  39671  23545  24178   9637   9460  48549\n",
            "   9043   9074  66982   9328  18622  14843   9460   9555   9633 107657\n",
            "   9202   9044   9557   9056    119    102      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56ryyrl6sYP1"
      },
      "source": [
        "print(len(label_ids_train2[kk][2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSJYPOBmGUkp"
      },
      "source": [
        "# 신경망 모델 작업"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjjP3nQ7L5QK"
      },
      "source": [
        "## 모델 정의 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpoNPTE3Mx2x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "48a81e606a6d4df1a566557a1355e592",
            "85157fa6bccd41bf9b7f7a5ae54bf3e6",
            "daa1f418a4ac4259bd799e89f4181570",
            "942eb6ebc03f4a9a94daddfac42b6445",
            "a61fabe916524ac0810fb2c03d907318",
            "cd35c2b415604fde92f86bb18ba34a5a",
            "f3d1499ebdcb478d98a5bbe0d29e1ece",
            "ff4c17e38bb644a98f95bc1442d53acd"
          ]
        },
        "outputId": "72550a11-9d95-4d3e-fa7b-f942eb6a8ac8"
      },
      "source": [
        "## Keras model -> https://keras.io/examples/nlp/semantic_similarity_with_bert/\n",
        "## LSTM, CRF -> https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb\n",
        "\n",
        "''' 신경망 모델 작업 현재 모델 model 3 '''\n",
        "\n",
        "MAX_LENGTH=max_seq_length   ## 위 bert 입력값 만들때 사용한 값\n",
        "BATCH_SIZE=32   ## 32 이상 코랩에서 안돌아가는 듯\n",
        "\n",
        "## BERT 레이어 만들기\n",
        "bert_model = TFBertModel.from_pretrained(BERT_MODEL, config= config)\n",
        "bert_model.trainable = True     ## BERT 파인튜닝 할 시 True\n",
        "## BERT 입력값 형식 맞춰주기\n",
        "input_ids = tf.keras.Input(shape=(MAX_LENGTH,), dtype=tf.int32,name=\"input_ids\"   )\n",
        "attention_masks = tf.keras.Input(shape=(MAX_LENGTH,),dtype=tf.int32,name=\"attention_masks\"   )\n",
        "token_type_ids = tf.keras.Input(shape=(MAX_LENGTH,), dtype=tf.int32,name=\"token_type_ids\"  )\n",
        "\n",
        "## 신경망 레이서 쌓기 시작\n",
        "sequence_output, pooled_output = bert_model(input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids)\n",
        "\n",
        "bi_lstm = tf.keras.layers.Bidirectional( tf.keras.layers.LSTM(64*4, return_sequences=True, recurrent_dropout=0.1) )(sequence_output)\n",
        "#timedist = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(64*1, activation = \"relu\"))(bi_lstm)\n",
        "\n",
        "#densed = tf.keras.layers.Dense(128*6, activation='relu')(timedist)\n",
        "#densed = tf.keras.layers.Dense(128*1, activation='relu')(densed)\n",
        "#dropout = tf.keras.layers.Dropout(0.15)(densed)\n",
        "\n",
        "#output = tf.keras.layers.Dense(num_labels, activation='softmax')(timedist)    ## output의 마지막 dense는 num_labels와 같아야해\n",
        "output = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_labels, activation = \"softmax\"))(bi_lstm)\n",
        "\n",
        "### CRF 는 tf.keras에서 현재 지원이 안되어서 포기\n",
        "#output = crf(timedist)\n",
        "#crf = CRF(algorithm = 'lbfgs', c1 = 0.1, c2 = 0.1, max_iterations = 100, all_possible_transitions = False)\n",
        "    # Applying hybrid pooling approach to bi_lstm sequence output.\n",
        "\n",
        "model = tf.keras.models.Model(  inputs=[input_ids, attention_masks, token_type_ids], outputs=output )\n",
        "\n",
        "model.compile( optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"] )\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48a81e606a6d4df1a566557a1355e592",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1083389348.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_masks (InputLayer)    [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "token_type_ids (InputLayer)     [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     ((None, 128, 768), ( 177853440   input_ids[0][0]                  \n",
            "                                                                 attention_masks[0][0]            \n",
            "                                                                 token_type_ids[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 128, 512)     2099200     tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, 128, 22)      11286       bidirectional[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 179,963,926\n",
            "Trainable params: 179,963,926\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWJ_DDbf8qtS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d59b5a67-4a0c-4553-b5e1-049cfd0b7e12"
      },
      "source": [
        "## 학습 시작\n",
        "\n",
        "history = model.fit(\n",
        "    x = [input_ids_train, token_ids_train, attention_masks_train],\n",
        "    y = np.array(label_ids_train2),\n",
        "    validation_data = ([input_ids_test, token_ids_test, attention_masks_test], np.array(label_ids_test2)),\n",
        "    batch_size = 16*4,\n",
        "    epochs=15,\n",
        "    #callbacks=[checkpointer],\n",
        "    use_multiprocessing=True,\n",
        "    workers=-1\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "300/300 [==============================] - 402s 1s/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.0808 - val_accuracy: 0.9814\n",
            "Epoch 2/15\n",
            "300/300 [==============================] - 406s 1s/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.0794 - val_accuracy: 0.9819\n",
            "Epoch 3/15\n",
            "300/300 [==============================] - 406s 1s/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.0827 - val_accuracy: 0.9813\n",
            "Epoch 4/15\n",
            "300/300 [==============================] - 409s 1s/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.0873 - val_accuracy: 0.9807\n",
            "Epoch 5/15\n",
            "300/300 [==============================] - 407s 1s/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.0873 - val_accuracy: 0.9808\n",
            "Epoch 6/15\n",
            "300/300 [==============================] - 407s 1s/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.0884 - val_accuracy: 0.9812\n",
            "Epoch 7/15\n",
            "300/300 [==============================] - 407s 1s/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.0900 - val_accuracy: 0.9812\n",
            "Epoch 8/15\n",
            "300/300 [==============================] - 405s 1s/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.0888 - val_accuracy: 0.9815\n",
            "Epoch 9/15\n",
            "300/300 [==============================] - 403s 1s/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0885 - val_accuracy: 0.9818\n",
            "Epoch 10/15\n",
            "300/300 [==============================] - 401s 1s/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.0984 - val_accuracy: 0.9809\n",
            "Epoch 11/15\n",
            "300/300 [==============================] - 397s 1s/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.0970 - val_accuracy: 0.9810\n",
            "Epoch 12/15\n",
            "300/300 [==============================] - 400s 1s/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.0978 - val_accuracy: 0.9811\n",
            "Epoch 13/15\n",
            "300/300 [==============================] - 398s 1s/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0953 - val_accuracy: 0.9816\n",
            "Epoch 14/15\n",
            "300/300 [==============================] - 400s 1s/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1001 - val_accuracy: 0.9817\n",
            "Epoch 15/15\n",
            "300/300 [==============================] - 400s 1s/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0978 - val_accuracy: 0.9819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8iAVh4UfaLR"
      },
      "source": [
        "'''모델 가중치만 저장. huggingface transformer bert 포함 시 model.save로 하면 에러 발생 '''\n",
        "#model.save_weights(path + '/ner_model3_2.h5') #epoch 15회\n",
        "model.save_weights(path + '/ner_model3_3.h5') #epoch 30회"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr_--ZeGfbkP"
      },
      "source": [
        "'''모델 가중치 불러오기 - 기존 학습 모델 가중치'''\n",
        "model.load_weights(path + '/ner_model3_1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQnsXQpK1PnY"
      },
      "source": [
        "# Evaluation\n",
        "y_pred1 = model.predict([input_ids_test, token_ids_test, attention_masks_test])\n",
        "y_pred = np.argmax(y_pred1, axis=-1)\n",
        "y_test_true = np.argmax(label_ids_test2, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FETM68op1wPL"
      },
      "source": [
        "# Convert the index to tag\n",
        "y_pred2 = [[idx2label_k[i] for i in row] for row in y_pred]\n",
        "y_test_true2 = [[idx2label_k[i] for i in row] for row in y_test_true]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ryJdFE_3-Ox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a7d08a6-b43a-4848-af9c-d3433b1659c3"
      },
      "source": [
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "report = flat_classification_report(y_pred=y_pred2, y_true=y_test_true2)\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Date       0.93      0.94      0.94      2875\n",
            "    Duration       0.68      0.74      0.71      1012\n",
            "         Etc       0.73      0.70      0.72      7493\n",
            "      Etc_No       0.87      0.91      0.89      2675\n",
            "     Etc_No.       0.87      0.89      0.88      3679\n",
            "    Location       0.74      0.84      0.79      4578\n",
            "       Money       0.97      0.99      0.98      1132\n",
            "        Name       0.93      0.94      0.93      9380\n",
            "        Null       1.00      1.00      1.00    395353\n",
            "           O       0.98      0.98      0.98    170615\n",
            "         Org       0.81      0.79      0.80     10991\n",
            "       Ratio       0.96      0.96      0.96      1176\n",
            "        Time       0.95      0.89      0.92       497\n",
            "\n",
            "    accuracy                           0.98    611456\n",
            "   macro avg       0.88      0.89      0.88    611456\n",
            "weighted avg       0.98      0.98      0.98    611456\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfGUmHvDMGrz"
      },
      "source": [
        "## 결과물 표시에 필요한 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzQObvNhP1JC"
      },
      "source": [
        "''' 입력된 복수의 문장들을 BERT모델의 input에 맞는 형식으로 리턴하는 함수 '''\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def convert_sentences_to_input(sentences):\n",
        "  input_id_list,attention_mask_list,token_type_id_list=[],[],[]\n",
        "  label_id_list=[]\n",
        "  \n",
        "  for x in sentences:\n",
        "  \n",
        "    tokens = []\n",
        "    label_ids = []\n",
        "\n",
        "    word_tokens = tokenizer.tokenize(x)\n",
        "    tokens.extend(word_tokens)\n",
        "  \n",
        "    special_tokens_count =  2\n",
        "    if len(tokens) > max_seq_length - special_tokens_count:\n",
        "      tokens = tokens[: (max_seq_length - special_tokens_count)]\n",
        "\n",
        "    inputs = tokenizer.encode_plus(tokens,add_special_tokens=True, max_length=max_seq_length)\n",
        "\n",
        "    input_ids, token_type_ids = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
        "    attention_masks = [1] * len(input_ids)\n",
        "\n",
        "    attention_mask_list.append(attention_masks)\n",
        "    input_id_list.append(input_ids)\n",
        "    token_type_id_list.append(token_type_ids)\n",
        "\n",
        "  return input_id_list,token_type_id_list,attention_mask_list\n",
        "\n",
        "## 위 함수를 이용해 변환 작업 \n",
        "#input_ids_train,token_ids_train,attention_masks_train,label_ids_train=convert_to_input(x_train_sentences,x_train_tags)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBDkOuPyEJgf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7a0af9fd-2ea5-41fb-fad3-1834f1a85cd5"
      },
      "source": [
        "'''# 문장을 넣으면 NER 정보가 포함된 문장으로 바꿔주는 함수 '''\n",
        "\n",
        "def sentence_ner(sentence, model, cs_input = 0.7) :\n",
        "  #버트 입력값 만들기\n",
        "  input_ids_sentence, token_ids_sentence, attention_masks_sentence = convert_sentences_to_input([sentence])\n",
        "  #버트 형식에 맞게 패딩작업\n",
        "  input_ids_sentence = pad_sequences(input_ids_sentence,maxlen=max_seq_length,dtype=\"long\",truncating=\"post\",padding=\"post\")\n",
        "  token_ids_sentence = pad_sequences(token_ids_sentence,maxlen=max_seq_length,dtype=\"long\",truncating=\"post\",padding=\"post\")\n",
        "  attention_masks_sentence = pad_sequences(attention_masks_sentence,maxlen=max_seq_length,dtype=\"long\",truncating=\"post\",padding=\"post\")\n",
        "  \n",
        "  bert_input = [input_ids_sentence, token_ids_sentence,attention_masks_sentence]\n",
        "  ner_score = model.predict(bert_input)\n",
        "  ner_output = np.argmax(ner_score, axis=-1)\n",
        "  \n",
        "  cs_no = 5\n",
        "  criteria_score = np.array(ner_score[0][:,2])\n",
        "  criteria_score.sort()\n",
        "  cs = criteria_score[-1*cs_no]\n",
        "  cs = cs_input\n",
        "\n",
        "  # 문장으로 표시해 주기\n",
        "  ner_sentence = ''\n",
        "  for i in range(len(input_ids_sentence[0])) :\n",
        "    piece = ner_output[0][i]\n",
        "\n",
        "    if input_ids_sentence[0][i]!=101 and input_ids_sentence[0][i]!=102 and input_ids_sentence[0][i]!=0 : \n",
        "      word = tokenizer.decode(input_ids_sentence[0][i:i+1])\n",
        "      if word[0:2]!=\"##\" : \n",
        "        if piece >1.5 and max(ner_score[0][i])>=cs:\n",
        "          ner_sentence = ner_sentence +' [' + idx2label_k.get(piece) + ']'\n",
        "        else :\n",
        "          ner_sentence +=  ' '\n",
        "          \n",
        "        if \"UNK\" in word :\n",
        "          ner_sentence +=  '\"'\n",
        "        elif \",\" in word :\n",
        "          ner_sentence = ner_sentence[:-1]\n",
        "          ner_sentence +=  ','\n",
        "        elif \".\" in word :\n",
        "          ner_sentence = ner_sentence[:-1]\n",
        "          ner_sentence +=  '.'\n",
        "        else :\n",
        "          ner_sentence +=  word.strip()\n",
        "\n",
        "      else :\n",
        "        ner_sentence +=  word[2:]\n",
        "  return ner_sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n  # 문장으로 표시해 주기\\n  ner_sentence = \\'\\'\\n  for i in range(len(input_ids_sentence[0])) :\\n    piece = ner_output[0][i]\\n\\n    if piece!=0 : \\n      word = tokenizer.decode(input_ids_sentence[0][i:i+1])\\n      if word[0:2]!=\"##\" : \\n        if piece >1.5 :\\n          ner_sentence = ner_sentence +\\' (\\' + idx2label.get(piece) + \\')\\'\\n        else :\\n          ner_sentence +=  \\' \\'\\n        ner_sentence +=  word\\n      else :\\n        ner_sentence +=  word[2:]\\n  return ner_sentence\\n\\n\\n  #print(\\'\\x1b[38;5;208m\\' + \\'다크 오렌지\\' + \\'\\x1b[0m\\')\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0uu7cGH_psP"
      },
      "source": [
        " ''' 입력문단에 model 돌려 NER정보를  포함해 출력 '''\n",
        "#!pip install kss\n",
        "#import kss\n",
        "\n",
        "def input2ner(sentences, model, cs_no = 0.7) :\n",
        "  #kss 문장분리기 : 문단을 문장별로 나눠 리스트에 저장해줌\n",
        "  #senbysen = kss.split_sentences(sentences)\n",
        "  senbysen = sentences.split('.')\n",
        "  print(\"\\n\\n원문\", senbysen,\"\\n\")\n",
        "\n",
        "  for i in range(len(senbysen)) :\n",
        "    ner_output = sentence_ner(senbysen[i]+\".\", model, cs_no)\n",
        "    print(ner_output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ndYTElAMU7X"
      },
      "source": [
        "## NER학습된 모델을 이용 예시 문장의 개체명 분석을 진행하는 부분"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv2bqEvi3jYO"
      },
      "source": [
        "# 고려((나무위키 개요))\n",
        "input_sentences = \"고려(高麗)는 918년부터 1392년까지 약 474년 동안 한반도 지역에 위치했던 전제군주정 불교 국가이다. 통일신라의 분열 후 고려, 후백제, 신라로 나뉘어 대치하던 후삼국시대를 왕건이 936년에 통일하였고, 이후 약 456년 동안 총 34명의 군주가 계승하여 1392년에 이성계의 역성혁명에 의해 조선이 건국되기까지 함경북도와 함경남도 그리고 평안북도의 일부 지역들을 제외한 한반도 대부분의 지역들을 지배하였다. 고려 전기 발해를 멸망시킨 요나라(거란족)와 송나라의 세력 균형 체제라는 국제적인 정세 속에서 고려는 요나라의 3차에 걸친 대규모 침략을 막아내며 자주국방의 위세를 뽐냈으나, 중기 이후 내부적으론 무신정권이 들어서고 외부적으론 금나라(여진족)의 부흥에 요와 북송이 차례로 털리고 금이 고려에 칭신을 요구하자 책봉 질서의 사대적 관계를 맺기 시작했고 이후 몽골 제국과 30년간의 처절한 항쟁 끝에 결국 항복하여 원 간섭기엔 심한 정치적 간섭을 받게 된다. 말이 좋아 항쟁이지 3차 침입 이후부터는 국토의 대부분이 쓸려나가는 동시에 육지의 백성들이 몽골군에게 참혹하게 도륙당하는 그야말로 악몽과도 같은 시기였다. 한편 당시 권력자 집단이었던 무신정권은 강화도에 숨어 호의호식하고 있었다. 다만 금과 남송을 포함한 유라시아 수십여개 국들이 몽골 제국에 쓸려나가는 동안, 고려는 비록 조정은 강화도에서 무능한 모습을 보였지만 백성들의 끈질긴 저항과 적절한 외교술로 나라 자체가 완전히 멸망하진 않았고, 이후 몽골의 부마국으로 존속하다가 고려 후기 원이 쇠퇴하자 공민왕 시절에 반원정책을 펼치면서 몽골의 내정간섭에서 벗어나게 된다.\" \n",
        "# 명량해전 위키\n",
        "input_sentences2 = \"이후 이순신은 붙잡힌 임준영 대신, 준사의 도움으로 풀려난 수봉에게 전갈을 받고 왜군의 전력을 파악한다. 그리고 명량의 흐름도 직접 관측한다. 명량 해전 당일, 이순신은 어머니의 위패에 절을 올리고 수봉에게 참전하고 싶거든 대장선의 노를 저으라 한 뒤 명량으로 올라오는 구루시마 선봉 왜선 330척과 맞선다. 구루시마는 당포 해전에서 죽은 형의 위패를 모신 아타케부네를 타고 적진 진군을 명한다. 이순신은 주저하는 다른 배를 놓아두고 앞장서서 적을 포격한다. 구루시마의 2진이 올 때, 대장선을 더 이상 지탱하기 힘들어지자 이순신은 닻을 끊고 해류 영향이 적은 섬 근처로 배를 옮길 것을 명한다. 그리고는 초요기(장수들을 부르는 명령기)를 올리나 아무도 오지 않는다. 이 때를 놓치지 않고 구루시마는 배를 대장선에 붙일 것을 명령한다. 이후 서너 척의 배에 타고 있던 왜군 병사와 함께 판옥선에서 조선군, 승병, 심지어 노를 젓던 민간인까지 말려든 백병전이 시작된다. 배가 포위되자 이순신은 포를 한 데 모아 터트리라 명령하고, 이는 성공하여 포위에서 풀리게 된다. 때맞춰 안위의 배가 지원을 위해 온다. 하지만 대장선의 화약이 다 떨어진 그 때, 화약과 조선인 포로를 실은 구루시마의 화공선이 대장선을 향해 다가온다. 대장선이 쏜 대장군전 덕에 풀려난 임준영이 아내에게 다른 배가 저 화공선을 보게 해달라는 신호를 보내고, 이를 알게 된 아내가 치마를 벗어 위로 펄럭인다. 구경하던 다른 백성들도 고함을 지르며 옷을 흔들자 이를 알게 된 중군장 김응함의 배가 포탄을 쏘아 대장선까지 닿기 전에 화약선을 터트리는 데 성공한다. 대장선이 멀쩡하다는 데 고무된 다른 배들이 서서히 참전한다. 그러나 구루시마를 제외한 다른 왜선들은 이순신을 두려워하며 전혀 지원하지 않는다. 여기서 이회는 이순신이 말한 '두려움을 이용한다'는 말의 뜻을 알게 된다. 판옥선이 아타케부네를 들이받으며 부수고, 형의 위패가 포격을 맞아 박살나는 걸 본 구루시마는 분노하여 직접 나선다. 이후 회오리 속에 양측의 배가 휘말린다. 구루시마는 직접 대장선으로 올라가 분투하지만 결국 죽고, 자신이 했던 그대로 목이 잘려 깃대에 걸리게 된다. 회오리에 휘말린 대장선은 백성들의 도움으로 겨우 탈출하는 데 성공하고, 도도 다카토라는 와키자카의 배가 피격당하는 것을 보고 난 뒤, '대도무문'이 적힌 깃발을 뒤로 한 채 퇴각을 명한다.\" \n",
        "# 국사교과서 - 갑오개혁\n",
        "input_sentences3 = \"일본의 침략과 급진적인 갑오·을미개혁의 실시로 대부분의 국민 사이에 반일 정서가 확산되었다. 또, 고종은 왕권을 제약하려는 개화 세력의 개혁에 불만을 가지고 있었고, 을미사변 후에는 신변의 위협까지 느끼게 되었다. 이에, 고종은 러시아 공사관으로 피신하였고(아관 파천, 1896), 개화파 정부는 무너졌다. 이후 고종은 단발령 철회, 의병 해산 권고 조치 등을 단행하였다.   아관 파천으로 국가의 자주성은 손상되었고, 광산, 산림 등에 대한 열강의 이권 침탈도 심해졌다. 이러한 상황에서 서재필 등은 독립 신문을 창간하여 서구의 자유 민권 사상을 소개하였으며, 독립 협회를 창립하였다(1896).   독립 협회는 강연회와 토론회 등을 통하여 민중에게 근대적 지식과 국권·민권 사상을 고취시켜, 광범한 사회 계층의 지지를 받는 단체로 발전하였다. 또, 독립 협회는 자주 국권, 자유 민권 등을 달성하려는 정치 운동을 전개하였으며, 만민 공동회와 관민 공동회를 개최하여 헌의 6조를 결의하였다.  그런데 독립 협회의 활동은 의회의 설립과 서구식 입헌 군주제 실현을 목표로 하였기 때문에 보수 세력과 대립하였다. 독립 협회는 보수 세력이 동원한 황국 협회의 방해를 받았고, 결국 3년 만에 해산되고 말았다.   한편, 고종은 러시아 공사관에서 약 1년 만에 환궁한 후, 자주 독립의 근대 국가를 세우려는 국민적 열망과 러시아를 견제하려는 국제 여론에 힘입어 대한 제국을 수립하였다(1897). 고종은 황제로 즉위하면서 연호를 광무(光武)로 하고, 자주 국가임을 국내외에 선포하였다.   대한 제국은 “옛 제도를 근본으로 하고 새로운 제도를 참작한다.”라는 구본신참(舊本新參)의 개혁 방향을 제시하고, 대한국 국제를 제정하여 황권을 강화하였다. 또, 양전 사업을 실시하여 지계를 발급하고, 상공업 진흥책을 추진하였다. 그러나 이러한 개혁 정책은 집권층의 보수적 성향과 열강의 간섭으로 큰 성과를 거두지는 못하였다. \"\n",
        "# 국사교과서 - 조선초기 외교관계\n",
        "input_sentences4 = \"명과 관계   조선은 사대 교린의 외교 정책을 일관되게 추진하였다. 명과는 태조 때 정도전이 중심이 되어 추진한 요동 정벌의 준비와 여진과의 관계를 둘러싸고 불편한 관계가 유지된 적도 있었지만, 태종 이후 양국 간의 관계가 좋아지면서 교류가 활발하였다.   조선은 명에 대해서 기본적으로 사대 정책을 유지하였으나, 명의 구체적인 내정 간섭은 없었다. 매년 정기적, 부정기적으로 사절을 교환하였고, 그 때 문화적, 경제적 교류가 활발하게 이루어졌다. 명에 대한 이와 같은 사대 외교는 왕권의 안정과 국제적 지위를 확보하려는 자주적인 실리 외교였고, 선진 문물을 흡수하려는 문화 외교인 동시에 일종의 공무역이었다.  여진과 관계   조선은 영토의 확보와 국경 지방의 안정을 위하여 여진에 대하여 적극적인 외교 정책을 펴 나갔다. 우선 태조에 의하여 일찍부터 두만강 지역이 개척되었다. 이어 세종 때에는 4군과 6진을 설치하여 압록강과 두만강을 경계로 하는, 오늘날과 같은 국경선을 확정하였다.   이후 여진에 대하여 조선은 회유와 토벌의 양면 정책을 취하였다. 조선은 여진족의 귀순을 장려하기 위하여 관직을 주거나 정착을 위한 토지와 주택을 주어 우리 주민으로 동화시켰다. 또, 사절의 왕래를 통한 무역을 허용하였고, 국경 지방인 경성과 경원에 무역소를 두고 국경 무역을 허락하였다. 그러나 이러한 교린 정책에도 불구하고 여진족은 자주 국경을 침입하여 약탈을 자행하였고, 이 때마다 조선에서는 군대를 동원하여 이들을 정벌하였다.  이와 함께 조선은 삼남 지방의 일부 주민을 대거 북방으로 이주시켜 압록강과 두만강 이남 지역을 개발하는 사민 정책을 실시하였고, 토착민을 토관으로 임명하여 민심을 수습하려 하였다.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OHQYVsOhreN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "161f37d1-f352-44ce-b8e2-ba2aa6abd857"
      },
      "source": [
        "# NER을 문장에 표시해주는 함수 실행\n",
        "input2ner(input_sentences, model)\n",
        "input2ner(input_sentences2, model)\n",
        "input2ner(input_sentences3, model)\n",
        "input2ner(input_sentences4, model, 0.9)  # 마지막에 optional한 숫자는 표시할 최소 정확도 값을 의미. 0.9를 넣으면 결과값 0.9 이상인 NER만 표시. 기본값 0.7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "원문 ['고려(高麗)는 918년부터 1392년까지 약 474년 동안 한반도 지역에 위치했던 전제군주정 불교 국가이다', ' 통일신라의 분열 후 고려, 후백제, 신라로 나뉘어 대치하던 후삼국시대를 왕건이 936년에 통일하였고, 이후 약 456년 동안 총 34명의 군주가 계승하여 1392년에 이성계의 역성혁명에 의해 조선이 건국되기까지 함경북도와 함경남도 그리고 평안북도의 일부 지역들을 제외한 한반도 대부분의 지역들을 지배하였다', ' 고려 전기 발해를 멸망시킨 요나라(거란족)와 송나라의 세력 균형 체제라는 국제적인 정세 속에서 고려는 요나라의 3차에 걸친 대규모 침략을 막아내며 자주국방의 위세를 뽐냈으나, 중기 이후 내부적으론 무신정권이 들어서고 외부적으론 금나라(여진족)의 부흥에 요와 북송이 차례로 털리고 금이 고려에 칭신을 요구하자 책봉 질서의 사대적 관계를 맺기 시작했고 이후 몽골 제국과 30년간의 처절한 항쟁 끝에 결국 항복하여 원 간섭기엔 심한 정치적 간섭을 받게 된다', ' 말이 좋아 항쟁이지 3차 침입 이후부터는 국토의 대부분이 쓸려나가는 동시에 육지의 백성들이 몽골군에게 참혹하게 도륙당하는 그야말로 악몽과도 같은 시기였다', ' 한편 당시 권력자 집단이었던 무신정권은 강화도에 숨어 호의호식하고 있었다', ' 다만 금과 남송을 포함한 유라시아 수십여개 국들이 몽골 제국에 쓸려나가는 동안, 고려는 비록 조정은 강화도에서 무능한 모습을 보였지만 백성들의 끈질긴 저항과 적절한 외교술로 나라 자체가 완전히 멸망하진 않았고, 이후 몽골의 부마국으로 존속하다가 고려 후기 원이 쇠퇴하자 공민왕 시절에 반원정책을 펼치면서 몽골의 내정간섭에서 벗어나게 된다', ''] \n",
            "\n",
            " [Org]고려 ( [Org]高 [Org]麗 ) 는 [Duration]918년부터 [Duration]1392년까지 약 [Duration]474년 동안 [Location]한반도 지역에 위치했던 전제군주정 [Org]불교 국가이다.\n",
            " [Org]통일신라의 분열 후 [Org]고려, [Org]후백제, [Org]신라로 나뉘어 대치하던 [Org]후삼국시대를 왕건이 [Date]936년에 통일하였고, 이후 약 456년 동안 총 [Etc_No]34명의 군주가 계승하여 [Date]1392년에 [Name]이성계의 역성혁명에 의해 [Org]조선이 건국되기까지 [Location]함경북도와 [Location]함경남도 그리고 [Location]평안북도의 일부 지역들을 제외한 [Location]한반도 대부분의 지역들을 지배하였다.\n",
            " [Org]고려 전기 발해를 멸망시킨 [Org]요나라 ( [Org]거란족 ) 와 [Org]송나라의 세력 균형 체제라는 국제적인 정세 속에서 [Org]고려는 [Org]요나라의 [Etc_No]3차에 걸친 대규모 침략을 막아내며 자주국방의 위세를 \", 중기 이후 내부적으론 무신정권이 들어서고 외부적으론 [Org]금나라 ( [Org]여진족 ) 의 부흥에 요와 [Org]북송이 차례로 털리고 금이 [Org]고려에 칭신을 요구하자 책봉 질서의 사대적 관\n",
            " 말이 좋아 항쟁이지 3차 침입 이후부터는 국토의 대부분이 쓸려나가는 동시에 육지의 백성들이 [Org]몽골군에게 참혹하게 도륙당하는 그야말로 악몽과도 같은 시기였다.\n",
            " 한편 당시 권력자 집단이었던 [Org]무신정권은 [Location]강화도에 숨어 호의호식하고 있었다.\n",
            " 다만 금과 남송을 포함한 [Location]유라시아 [Etc_No]수십여개 국들이 [Org]몽골 [Org]제국에 쓸려나가는 동안, [Org]고려는 비록 조정은 강화도에서 무능한 모습을 보였지만 백성들의 끈질긴 저항과 적절한 외교술로 나라 자체가 완전히 멸망하진 않았고, 이후 [Org]몽골의 부마국으로 존속하다가 [Org]고려 후기 원이 쇠퇴하자 [Name]공민왕 시절에 반원정책을 펼치면서 [Org]몽골의 내정간섭에서 벗어나게 된다.\n",
            ".\n",
            "\n",
            "\n",
            "원문 ['이후 이순신은 붙잡힌 임준영 대신, 준사의 도움으로 풀려난 수봉에게 전갈을 받고 왜군의 전력을 파악한다', ' 그리고 명량의 흐름도 직접 관측한다', ' 명량 해전 당일, 이순신은 어머니의 위패에 절을 올리고 수봉에게 참전하고 싶거든 대장선의 노를 저으라 한 뒤 명량으로 올라오는 구루시마 선봉 왜선 330척과 맞선다', ' 구루시마는 당포 해전에서 죽은 형의 위패를 모신 아타케부네를 타고 적진 진군을 명한다', ' 이순신은 주저하는 다른 배를 놓아두고 앞장서서 적을 포격한다', ' 구루시마의 2진이 올 때, 대장선을 더 이상 지탱하기 힘들어지자 이순신은 닻을 끊고 해류 영향이 적은 섬 근처로 배를 옮길 것을 명한다', ' 그리고는 초요기(장수들을 부르는 명령기)를 올리나 아무도 오지 않는다', ' 이 때를 놓치지 않고 구루시마는 배를 대장선에 붙일 것을 명령한다', ' 이후 서너 척의 배에 타고 있던 왜군 병사와 함께 판옥선에서 조선군, 승병, 심지어 노를 젓던 민간인까지 말려든 백병전이 시작된다', ' 배가 포위되자 이순신은 포를 한 데 모아 터트리라 명령하고, 이는 성공하여 포위에서 풀리게 된다', ' 때맞춰 안위의 배가 지원을 위해 온다', ' 하지만 대장선의 화약이 다 떨어진 그 때, 화약과 조선인 포로를 실은 구루시마의 화공선이 대장선을 향해 다가온다', ' 대장선이 쏜 대장군전 덕에 풀려난 임준영이 아내에게 다른 배가 저 화공선을 보게 해달라는 신호를 보내고, 이를 알게 된 아내가 치마를 벗어 위로 펄럭인다', ' 구경하던 다른 백성들도 고함을 지르며 옷을 흔들자 이를 알게 된 중군장 김응함의 배가 포탄을 쏘아 대장선까지 닿기 전에 화약선을 터트리는 데 성공한다', ' 대장선이 멀쩡하다는 데 고무된 다른 배들이 서서히 참전한다', ' 그러나 구루시마를 제외한 다른 왜선들은 이순신을 두려워하며 전혀 지원하지 않는다', \" 여기서 이회는 이순신이 말한 '두려움을 이용한다'는 말의 뜻을 알게 된다\", ' 판옥선이 아타케부네를 들이받으며 부수고, 형의 위패가 포격을 맞아 박살나는 걸 본 구루시마는 분노하여 직접 나선다', ' 이후 회오리 속에 양측의 배가 휘말린다', ' 구루시마는 직접 대장선으로 올라가 분투하지만 결국 죽고, 자신이 했던 그대로 목이 잘려 깃대에 걸리게 된다', \" 회오리에 휘말린 대장선은 백성들의 도움으로 겨우 탈출하는 데 성공하고, 도도 다카토라는 와키자카의 배가 피격당하는 것을 보고 난 뒤, '대도무문'이 적힌 깃발을 뒤로 한 채 퇴각을 명한다\", ''] \n",
            "\n",
            " 이후 [Name]이순신은 붙잡힌 [Name]임준영 대신, 준사의 도움으로 풀려난 [Name]수봉에게 전갈을 받고 [Org]왜군의 전력을 파악한다.\n",
            " 그리고 명량의 흐름도 직접 관측한다.\n",
            " [Location]명량 해전 당일, [Name]이순신은 어머니의 위패에 절을 올리고 수봉에게 참전하고 싶거든 대장선의 노를 저으라 한 뒤 명량으로 올라오는 [Location]구루시마 선봉 왜선 [Etc_No]330척과 맞선다.\n",
            " [Name]구루시마는 [Location]당포 해전에서 죽은 형의 위패를 모신 [Name]아타케부네를 타고 적진 진군을 명한다.\n",
            " [Name]이순신은 주저하는 다른 배를 놓아두고 앞장서서 적을 포격한다.\n",
            " 구루시마의 [Etc_No]2진이 올 때, 대장선을 더 이상 지탱하기 힘들어지자 [Name]이순신은 \" 끊고 해류 영향이 적은 섬 근처로 배를 옮길 것을 명한다.\n",
            " 그리고는 초요기 ( 장수들을 부르는 명령기 ) 를 올리나 아무도 오지 않는다.\n",
            " 이 때를 놓치지 않고 [Name]구루시마는 배를 대장선에 붙일 것을 명령한다.\n",
            " 이후 [Etc_No]서너 [Etc_No.]척의 배에 타고 있던 [Org]왜군 병사와 함께 [Location]판옥선에서 [Org]조선군, 승병, 심지어 노를 \" 민간인까지 말려든 백병전이 시작된다.\n",
            " 배가 포위되자 [Name]이순신은 포를 한 데 모아 터트리라 명령하고, 이는 성공하여 포위에서 풀리게 된다.\n",
            " 때맞춰 안위의 배가 지원을 위해 온다.\n",
            " 하지만 대장선의 화약이 다 떨어진 그 때, 화약과 조선인 포로를 실은 구루시마의 화공선이 대장선을 향해 다가온다.\n",
            " 대장선이 쏜 대장군전 덕에 풀려난 [Name]임준영이 아내에게 다른 배가 저 화공선을 보게 해달라는 신호를 보내고, 이를 알게 된 아내가 치마를 벗어 위로 펄럭인다.\n",
            " 구경하던 다른 백성들도 고함을 지르며 옷을 흔들자 이를 알게 된 중군장 [Name]김응함의 배가 포탄을 쏘아 대장선까지 닿기 전에 화약선을 터트리는 데 성공한다.\n",
            " 대장선이 \" 데 고무된 다른 배들이 서서히 참전한다.\n",
            " 그러나 [Location]구루시마를 제외한 다른 왜선들은 [Name]이순신을 두려워하며 전혀 지원하지 않는다.\n",
            " 여기서 [Name]이회는 [Name]이순신이 말한 ' 두려움을 이용한다 ' 는 말의 뜻을 알게 된다.\n",
            " 판옥선이 [Name]아타케부네를 들이받으며 부수고, 형의 위패가 포격을 맞아 박살나는 걸 본 [Name]구루시마는 분노하여 직접 나선다.\n",
            " 이후 회오리 속에 양측의 배가 휘말린다.\n",
            " [Name]구루시마는 직접 대장선으로 올라가 분투하지만 결국 죽고, 자신이 했던 그대로 목이 잘려 깃대에 걸리게 된다.\n",
            " 회오리에 휘말린 대장선은 백성들의 도움으로 겨우 탈출하는 데 성공하고, [Name]도도 [Name]다카토라는 [Name]와키자카의 배가 피격당하는 것을 보고 난 뒤, ' 대도무문 ' 이 적힌 깃발을 뒤로 한 채 퇴각을 명한다.\n",
            ".\n",
            "\n",
            "\n",
            "원문 ['일본의 침략과 급진적인 갑오·을미개혁의 실시로 대부분의 국민 사이에 반일 정서가 확산되었다', ' 또, 고종은 왕권을 제약하려는 개화 세력의 개혁에 불만을 가지고 있었고, 을미사변 후에는 신변의 위협까지 느끼게 되었다', ' 이에, 고종은 러시아 공사관으로 피신하였고(아관 파천, 1896), 개화파 정부는 무너졌다', ' 이후 고종은 단발령 철회, 의병 해산 권고 조치 등을 단행하였다', '   아관 파천으로 국가의 자주성은 손상되었고, 광산, 산림 등에 대한 열강의 이권 침탈도 심해졌다', ' 이러한 상황에서 서재필 등은 독립 신문을 창간하여 서구의 자유 민권 사상을 소개하였으며, 독립 협회를 창립하였다(1896)', '   독립 협회는 강연회와 토론회 등을 통하여 민중에게 근대적 지식과 국권·민권 사상을 고취시켜, 광범한 사회 계층의 지지를 받는 단체로 발전하였다', ' 또, 독립 협회는 자주 국권, 자유 민권 등을 달성하려는 정치 운동을 전개하였으며, 만민 공동회와 관민 공동회를 개최하여 헌의 6조를 결의하였다', '  그런데 독립 협회의 활동은 의회의 설립과 서구식 입헌 군주제 실현을 목표로 하였기 때문에 보수 세력과 대립하였다', ' 독립 협회는 보수 세력이 동원한 황국 협회의 방해를 받았고, 결국 3년 만에 해산되고 말았다', '   한편, 고종은 러시아 공사관에서 약 1년 만에 환궁한 후, 자주 독립의 근대 국가를 세우려는 국민적 열망과 러시아를 견제하려는 국제 여론에 힘입어 대한 제국을 수립하였다(1897)', ' 고종은 황제로 즉위하면서 연호를 광무(光武)로 하고, 자주 국가임을 국내외에 선포하였다', '   대한 제국은 “옛 제도를 근본으로 하고 새로운 제도를 참작한다', '”라는 구본신참(舊本新參)의 개혁 방향을 제시하고, 대한국 국제를 제정하여 황권을 강화하였다', ' 또, 양전 사업을 실시하여 지계를 발급하고, 상공업 진흥책을 추진하였다', ' 그러나 이러한 개혁 정책은 집권층의 보수적 성향과 열강의 간섭으로 큰 성과를 거두지는 못하였다', ' '] \n",
            "\n",
            " [Org]일본의 침략과 급진적인 [Etc]갑오 · [Etc]을미개혁의 실시로 대부분의 국민 사이에 반일 정서가 확산되었다.\n",
            " 또, [Name]고종은 왕권을 제약하려는 개화 세력의 개혁에 불만을 가지고 있었고, [Etc]을미사변 후에는 신변의 위협까지 느끼게 되었다.\n",
            " 이에, [Name]고종은 [Location]러시아 공사관으로 피신하였고 ( [Etc]아관 [Etc]파천, [Date]1896 ), 개화파 정부는 무너졌다.\n",
            " 이후 고종은 단발령 철회, 의병 해산 권고 조치 등을 단행하였다.\n",
            " 아관 파천으로 국가의 자주성은 손상되었고, 광산, 산림 등에 대한 열강의 이권 침탈도 심해졌다.\n",
            " 이러한 상황에서 [Name]서재필 등은 독립 신문을 창간하여 서구의 자유 민권 사상을 소개하였으며, [Org]독립 [Org]협회를 창립하였다 ( [Date]1896 ).\n",
            " [Org]독립 [Org]협회는 강연회와 토론회 등을 통하여 민중에게 근대적 지식과 국권 · 민권 사상을 고취시켜, 광범한 사회 계층의 지지를 받는 단체로 발전하였다.\n",
            " 또, [Org]독립 [Org]협회는 자주 국권, 자유 민권 등을 달성하려는 정치 운동을 전개하였으며, 만민 공동회와 관민 공동회를 개최하여 헌의 [Etc_No]6조를 결의하였다.\n",
            " 그런데 독립 협회의 활동은 의회의 설립과 서구식 입헌 군주제 실현을 목표로 하였기 때문에 보수 세력과 대립하였다.\n",
            " 독립 협회는 보수 세력이 동원한 황국 협회의 방해를 받았고, 결국 3년 만에 해산되고 말았다.\n",
            " 한편, [Name]고종은 러시아 공사관에서 약 [Etc_No]1년 만에 환궁한 후, 자주 독립의 근대 국가를 세우려는 국민적 열망과 [Org]러시아를 견제하려는 국제 여론에 힘입어 [Org]대한 [Org]제국을 수립하였다 ( [Date]1897 ).\n",
            " [Name]고종은 황제로 즉위하면서 연호를 [Date]광무 ( [Date]光 [Date]武 ) 로 하고, 자주 국가임을 국내외에 선포하였다.\n",
            " [Org]대한 [Org]제국은 \" 옛 제도를 근본으로 하고 새로운 제도를 참작한다.\n",
            " \" 라는 [Etc]구본신참 ( [Etc]舊 [Etc]本 [Etc]新 [Etc]參 ) 의 개혁 방향을 제시하고, 대한국 국제를 제정하여 황권을 강화하였다.\n",
            " 또, 양전 사업을 실시하여 지계를 발급하고, 상공업 진흥책을 추진하였다.\n",
            " 그러나 이러한 개혁 정책은 집권층의 보수적 성향과 열강의 간섭으로 큰 성과를 거두지는 못하였다.\n",
            ".\n",
            "\n",
            "\n",
            "원문 ['명과 관계   조선은 사대 교린의 외교 정책을 일관되게 추진하였다', ' 명과는 태조 때 정도전이 중심이 되어 추진한 요동 정벌의 준비와 여진과의 관계를 둘러싸고 불편한 관계가 유지된 적도 있었지만, 태종 이후 양국 간의 관계가 좋아지면서 교류가 활발하였다', '   조선은 명에 대해서 기본적으로 사대 정책을 유지하였으나, 명의 구체적인 내정 간섭은 없었다', ' 매년 정기적, 부정기적으로 사절을 교환하였고, 그 때 문화적, 경제적 교류가 활발하게 이루어졌다', ' 명에 대한 이와 같은 사대 외교는 왕권의 안정과 국제적 지위를 확보하려는 자주적인 실리 외교였고, 선진 문물을 흡수하려는 문화 외교인 동시에 일종의 공무역이었다', '  여진과 관계   조선은 영토의 확보와 국경 지방의 안정을 위하여 여진에 대하여 적극적인 외교 정책을 펴 나갔다', ' 우선 태조에 의하여 일찍부터 두만강 지역이 개척되었다', ' 이어 세종 때에는 4군과 6진을 설치하여 압록강과 두만강을 경계로 하는, 오늘날과 같은 국경선을 확정하였다', '   이후 여진에 대하여 조선은 회유와 토벌의 양면 정책을 취하였다', ' 조선은 여진족의 귀순을 장려하기 위하여 관직을 주거나 정착을 위한 토지와 주택을 주어 우리 주민으로 동화시켰다', ' 또, 사절의 왕래를 통한 무역을 허용하였고, 국경 지방인 경성과 경원에 무역소를 두고 국경 무역을 허락하였다', ' 그러나 이러한 교린 정책에도 불구하고 여진족은 자주 국경을 침입하여 약탈을 자행하였고, 이 때마다 조선에서는 군대를 동원하여 이들을 정벌하였다', '  이와 함께 조선은 삼남 지방의 일부 주민을 대거 북방으로 이주시켜 압록강과 두만강 이남 지역을 개발하는 사민 정책을 실시하였고, 토착민을 토관으로 임명하여 민심을 수습하려 하였다', ''] \n",
            "\n",
            " 명과 관계 [Org]조선은 사대 교린의 외교 정책을 일관되게 추진하였다.\n",
            " 명과는 태조 때 정도전이 중심이 되어 추진한 요동 정벌의 준비와 여진과의 관계를 둘러싸고 불편한 관계가 유지된 적도 있었지만, 태종 이후 양국 간의 관계가 좋아지면서 교류가 활발하였다.\n",
            " 조선은 명에 대해서 기본적으로 사대 정책을 유지하였으나, 명의 구체적인 내정 간섭은 없었다.\n",
            " 매년 정기적, 부정기적으로 사절을 교환하였고, 그 때 문화적, 경제적 교류가 활발하게 이루어졌다.\n",
            " 명에 대한 이와 같은 사대 외교는 왕권의 안정과 국제적 지위를 확보하려는 자주적인 실리 외교였고, 선진 문물을 흡수하려는 문화 외교인 동시에 일종의 공무역이었다.\n",
            " [Location]여진과 관계 [Org]조선은 영토의 확보와 국경 지방의 안정을 위하여 [Location]여진에 대하여 적극적인 외교 정책을 펴 나갔다.\n",
            " 우선 태조에 의하여 일찍부터 [Location]두만강 지역이 개척되었다.\n",
            " 이어 세종 때에는 [Etc_No]4군과 [Etc_No]6진을 설치하여 [Location]압록강과 [Location]두만강을 경계로 하는, 오늘날과 같은 국경선을 확정하였다.\n",
            " 이후 [Location]여진에 대하여 조선은 회유와 토벌의 양면 정책을 취하였다.\n",
            " [Org]조선은 여진족의 귀순을 장려하기 위하여 관직을 주거나 정착을 위한 토지와 주택을 주어 우리 주민으로 동화시켰다.\n",
            " 또, 사절의 왕래를 통한 무역을 허용하였고, 국경 지방인 [Location]경성과 경원에 무역소를 두고 국경 무역을 허락하였다.\n",
            " 그러나 이러한 교린 정책에도 불구하고 여진족은 자주 국경을 침입하여 약탈을 자행하였고, 이 때마다 [Org]조선에서는 군대를 동원하여 이들을 정벌하였다.\n",
            " 이와 함께 조선은 [Location]삼남 지방의 일부 주민을 대거 북방으로 이주시켜 [Location]압록강과 [Location]두만강 이남 지역을 개발하는 사민 정책을 실시하였고, 토착민을 토관으로 임명하여 민심을 수습하려 하였다.\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}